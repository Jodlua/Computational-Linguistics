{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COG403: Problem 2 of Problem Set 2: Semantic Networks\n",
    "\n",
    "### All 3 problems for Problem Set 2 Due 1 November 2018, 2 pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question you will be building and experimenting with a semantic network based on the Small World of Words data, to do a partial replication of the Abbott et al. (2015) experiments on a larger free association data set. To build the graph for the semantic network, we will be using the Python library `networkx`. Below are some examples of how to use this library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_graph.nodes() => ['c', 'd', 'a', 'b']\n",
      "example_graph.edges() => [('c', 'd'), ('a', 'c'), ('a', 'd'), ('a', 'b')]\n",
      "'a' in example_graph => True\n",
      "example_graph['a'] => {'c': {'weight': 0.2}, 'd': {'weight': 0.4}, 'b': {'weight': 0.1}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JoshGelua/anaconda3/lib/python3.5/site-packages/networkx/drawing/nx_pylab.py:611: MatplotlibDeprecationWarning: isinstance(..., numbers.Number)\n",
      "  if cb.is_numlike(alpha):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from provided_functions import plot_graph\n",
    "\n",
    "# initialize graph\n",
    "example_graph = nx.DiGraph()\n",
    "\n",
    "# add nodes\n",
    "example_graph.add_node('a')\n",
    "example_graph.add_node('a')\n",
    "example_graph.add_nodes_from(['b', 'c', 'd'])\n",
    "example_graph.add_nodes_from(['b', 'c', 'd'])\n",
    "\n",
    "# add edges\n",
    "example_graph.add_edge('a', 'b', weight=0.1)\n",
    "example_graph.add_edge('a', 'c', weight=0.2)\n",
    "example_graph.add_edge('c', 'd', weight=0.1)\n",
    "example_graph.add_edge('a', 'd', weight=0.4)\n",
    "\n",
    "print(\"example_graph.nodes() => {}\".format(example_graph.nodes()))\n",
    "print(\"example_graph.edges() => {}\".format(example_graph.edges()))\n",
    "print(\"'a' in example_graph => {}\".format('a' in example_graph))\n",
    "print(\"example_graph['a'] => {}\".format(example_graph['a']))\n",
    "\n",
    "# use provided function to plot graph\n",
    "plot_graph(example_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Write a function to build a semantic network from the Small World of Words data using `networkx.DiGraph`. Call your function `get_swow_graph` and write it according to the specifications below. Print a list of all the node labels of nodes that *dog* has an outgoing edge to, as well as the weight of each edge.\n",
    "\n",
    "Note: do NOT print the entire graph, since it is so large.\n",
    "\n",
    "Note: only words that occur as cues should be included as nodes in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tired': {'weight': 0.009389671361502348}, 'puppy': {'weight': 0.046948356807511735}, 'bird': {'weight': 0.004694835680751174}, 'happy': {'weight': 0.018779342723004695}, 'walk': {'weight': 0.014084507042253521}, 'nap': {'weight': 0.004694835680751174}, 'caring': {'weight': 0.004694835680751174}, 'animal': {'weight': 0.03755868544600939}, 'bitch': {'weight': 0.004694835680751174}, 'God': {'weight': 0.009389671361502348}, 'friend': {'weight': 0.07042253521126761}, 'tail': {'weight': 0.004694835680751174}, 'hair': {'weight': 0.004694835680751174}, 'days': {'weight': 0.009389671361502348}, 'stubborn': {'weight': 0.004694835680751174}, 'log': {'weight': 0.004694835680751174}, 'faithful': {'weight': 0.004694835680751174}, 'mate': {'weight': 0.004694835680751174}, 'ball': {'weight': 0.009389671361502348}, 'frog': {'weight': 0.004694835680751174}, 'fish': {'weight': 0.004694835680751174}, 'fear': {'weight': 0.004694835680751174}, 'fun': {'weight': 0.009389671361502348}, 'elephant': {'weight': 0.004694835680751174}, 'home': {'weight': 0.004694835680751174}, 'golden': {'weight': 0.009389671361502348}, 'pig': {'weight': 0.009389671361502348}, 'wolf': {'weight': 0.004694835680751174}, 'play': {'weight': 0.004694835680751174}, 'buddy': {'weight': 0.004694835680751174}, 'loyal': {'weight': 0.009389671361502348}, 'work': {'weight': 0.004694835680751174}, 'rabbit': {'weight': 0.004694835680751174}, 'cute': {'weight': 0.009389671361502348}, 'tongue': {'weight': 0.014084507042253521}, 'waste': {'weight': 0.004694835680751174}, 'bark': {'weight': 0.03755868544600939}, 'kiss': {'weight': 0.004694835680751174}, 'yard': {'weight': 0.004694835680751174}, 'world': {'weight': 0.004694835680751174}, 'companion': {'weight': 0.018779342723004695}, 'snake': {'weight': 0.004694835680751174}, 'gone': {'weight': 0.004694835680751174}, 'house': {'weight': 0.004694835680751174}, 'follow': {'weight': 0.009389671361502348}, 'go': {'weight': 0.004694835680751174}, 'track': {'weight': 0.004694835680751174}, 'mean': {'weight': 0.004694835680751174}, 'black': {'weight': 0.004694835680751174}, 'ears': {'weight': 0.004694835680751174}, 'lap': {'weight': 0.004694835680751174}, 'dead': {'weight': 0.004694835680751174}, 'friendly': {'weight': 0.004694835680751174}, 'lead': {'weight': 0.009389671361502348}, 'run': {'weight': 0.018779342723004695}, 'dog': {'weight': 0.004694835680751174}, 'stink': {'weight': 0.004694835680751174}, 'annoying': {'weight': 0.004694835680751174}, 'mouse': {'weight': 0.004694835680751174}, 'least': {'weight': 0.004694835680751174}, 'rat': {'weight': 0.004694835680751174}, 'eat': {'weight': 0.004694835680751174}, 'horse': {'weight': 0.009389671361502348}, 'day': {'weight': 0.004694835680751174}, 'amazing': {'weight': 0.004694835680751174}, 'pant': {'weight': 0.004694835680751174}, 'pet': {'weight': 0.07981220657276995}, 'guard': {'weight': 0.004694835680751174}, 'bite': {'weight': 0.014084507042253521}, 'love': {'weight': 0.018779342723004695}, 'cat': {'weight': 0.23943661971830985}, 'bone': {'weight': 0.03755868544600939}, 'cow': {'weight': 0.004694835680751174}}\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from provided_functions import plot_graph\n",
    "from data.animals import ANIMAL_TO_CATEGORIES\n",
    "import csv\n",
    "from collections import Counter\n",
    "SWOW_FILE = 'data/SWOW-EN.R100.csv'\n",
    "\n",
    "\n",
    "def get_swow_graph(node_threshold=5):\n",
    "    \"\"\"\n",
    "    node_threshold: int -- the number of times a word must occur in the SWOW data to be \n",
    "    added as a node to your graph.\n",
    "    \n",
    "    Generates a directed, weighted networkx.DiGraph where:\n",
    "        1. Nodes represent cues from the SWOW data that occur at least node_threhsold times.\n",
    "           Note: the word 'NA' should not occur as a node.\n",
    "        2. Outgoing edges from each node sum to 1. These should be proportional to the number of times\n",
    "           each node occurs as a response to the cue associated with the given node.\n",
    "        3. The node 'animal' is treated a special case. The outgoing edges from the node 'animal' should\n",
    "           have a uniform probability over all cues in the SWOW data that are keys in the dict\n",
    "           ANIMAL_TO_CATEGORIES in the data/animals.py file.\n",
    "    \"\"\"  \n",
    "    sum_of_keys = 0\n",
    "    swow_graph = nx.DiGraph()\n",
    "    node_weights = {}\n",
    "    with open(SWOW_FILE, 'rt') as f:\n",
    "        reader = csv.reader(f)\n",
    "        SWOW_entries = list(reader)\n",
    "    for index in SWOW_entries:\n",
    "        if index[-4] in node_weights:\n",
    "            node_weights[index[-4]] += 1\n",
    "        else:\n",
    "            node_weights[index[-4]] = 1\n",
    "                                    \n",
    "    node_weights = {node:weights for node, weights in node_weights.items() if weights >= node_threshold}\n",
    "    weights = {}\n",
    "    for node in node_weights:\n",
    "        weights[node] = []\n",
    "    with open(SWOW_FILE, 'rt') as f:\n",
    "        reader = csv.reader(f)\n",
    "        SWOW_entries = list(reader)\n",
    "    for index in SWOW_entries:\n",
    "        if index[-4] in node_weights:\n",
    "            if index [-3] in node_weights:\n",
    "                weights[index[-4]].append(index[-3])\n",
    "            if index [-2] in node_weights:\n",
    "                weights[index[-4]].append(index[-2])\n",
    "            if index [-1] in node_weights:\n",
    "                weights[index[-4]].append(index[-1])\n",
    "    for node in weights:\n",
    "        swow_graph.add_node(node)\n",
    "    for cues in ANIMAL_TO_CATEGORIES:\n",
    "        if cues in node_weights:\n",
    "            sum_of_keys += 1\n",
    "    for cues in ANIMAL_TO_CATEGORIES:\n",
    "        if cues in node_weights:\n",
    "            swow_graph.add_edge('animal', cues, weight=(1/sum_of_keys))\n",
    "    for node in weights:\n",
    "        connecting_node_weight = []\n",
    "        length_of_node = len(weights[node])\n",
    "        if node != 'animal':\n",
    "            for connecting in weights[node]:\n",
    "                weight = weights[node].count(connecting) / length_of_node\n",
    "                if (connecting, weight) not in connecting_node_weight:\n",
    "                    connecting_node_weight.append((connecting, weight))\n",
    "            for connecting, weight in connecting_node_weight:\n",
    "                swow_graph.add_edge(node, connecting, weight=weight)\n",
    "\n",
    "    return swow_graph\n",
    "    \n",
    "    \n",
    "swow_graph = get_swow_graph()\n",
    "print(swow_graph['dog'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)\n",
    "\n",
    "In this step, you will visualize your graph using the function `plot_graph` in `provided_functions.py`. Because the actual graph has thousands of nodes, we will visualize a portion of the graph. Write a function `get_subgraph` based on the specifications below. Call `get_subgraph` on your graph with three start nodes: *dog*, *turtle*, and *animal*. For *dog* and *turtle*, use `length=2` and `threshold=0.05`. For *animal*, use `length=1` and `threshold=0`. Call `plot_graph` on each subgraph.\n",
    "\n",
    "Hint: use the `subgraph` method of networkx graphs.\n",
    "\n",
    "Note: By default, the `plot_graph` function plots a graph as undirected. For your graphs for this question, please use the default to print them without the arrows. If you are curious and want to experiment, you can make it show the arrows by setting `arrows=True`. The reason it's set to `False` by default is that the way `matplotlib` renders the arrows decreases the interpretability of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e3a8ce3cd42c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mturtle_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_subgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'turtle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mdog_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_subgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dog'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0manimal_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_subgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'animal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'G' is not defined"
     ]
    }
   ],
   "source": [
    "from provided_functions import plot_graph\n",
    " \n",
    " \n",
    "def get_subgraph(G, start, length=2, threshold=0.05):\n",
    "    \"\"\"\n",
    "    G: networkx.DiGraph -- semantic network of SWOW data\n",
    "    start: str -- name of node to start with\n",
    "    length: int -- the maximum distance a node can be from start to be included in the result.\n",
    "        The length of a path through the graph is the number of edges needed to get from\n",
    "        the start node to the end node (e.g. the path from A->B->C is 2).\n",
    "    threshold: float -- the minimum edge weight required for an edge to be added to the graph\n",
    "    \n",
    "    Return a subgraph of G based on a search starting at start. Only include nodes in your graph that \n",
    "    have a distance of length or less from your start node. When searching, only add nodes that are\n",
    "    connected to your graph by an edge with weight threshold or higher.\n",
    "    \"\"\"\n",
    "    sg = G[start]\n",
    "    nodes = [start]\n",
    "    \n",
    "    for k in sg:\n",
    "        if sg[k]['weight'] >= threshold:\n",
    "            nodes.append(k)\n",
    "            \n",
    "    i = 1\n",
    "    while i < length:\n",
    "        for node in nodes[1:]:\n",
    "            subg = G[node]\n",
    "            for k in subg:\n",
    "                if subg[k]['weight'] >= threshold and k not in nodes:\n",
    "                    nodes.append(k)\n",
    "        i += 1\n",
    "    \n",
    "    \n",
    "    return G.subgraph(nodes)\n",
    "\n",
    "turtle_graph = get_subgraph(G, 'turtle', length=2, threshold=0.05)\n",
    "dog_graph = get_subgraph(G, 'dog',length=2, threshold=0.05)\n",
    "animal_graph = get_subgraph(G, 'animal', length=1, threshold=0)\n",
    "\n",
    "plot_graph(turtle_graph)\n",
    "plot_graph(dog_graph)\n",
    "plot_graph(animal_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)\n",
    "\n",
    "Write two functions `get_most_likely_walk` and `get_least_likely_walk` that find the most and least likely walks from a given start node. Implement your functions according to the docstrings below.\n",
    "\n",
    "Call your functions with the graph from part a. In both cases, set `start = 'dog'` and `walk_length = 10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_likely_walk(G, start, walk_length):\n",
    "    \"\"\"\n",
    "    G: networkx.DiGraph -- semantic network of SWOW data\n",
    "    start: str -- name of node to start with\n",
    "    walk_length: the length of the walk to return.\n",
    "    \n",
    "    Return a list of length walk_length representing a walk. Do not include start in your\n",
    "    result. Each node in your walk should be most likely node given the previous node. In\n",
    "    other words, it should be the node that the previous node has the highest weighted\n",
    "    outgoing edge to.\n",
    "    \n",
    "    Do not allow repeats in your walk. For example, say 'fox' is your start node and\n",
    "    'den' is the most likely node to follow 'fox'. Even if 'fox' is also the most\n",
    "    likely node to follow 'den', it should not be revisited after we've seen it. In this case,\n",
    "    you should select the second highest weighted edge.\n",
    "    \"\"\"\n",
    "    walk = []\n",
    "    point = G[start]\n",
    "    prob = 0\n",
    "    for steps in point:\n",
    "        if point[steps]['weight'] > prob:\n",
    "            prob = point[steps]['weight']\n",
    "            step = steps\n",
    "    walk.append(step)\n",
    "    for i in range(walk_length-1):\n",
    "        after_step = G[step]\n",
    "        prob = 0\n",
    "        for steps in after_step:\n",
    "            if after_step[steps]['weight'] > prob and steps not in walk and steps != start:\n",
    "                mw = after_step[steps]['weight']\n",
    "                step = steps\n",
    "        walk.append(step)\n",
    "    \n",
    "    return walk \n",
    "print(\"Starting at dog, the most likely walk is:\")\n",
    "print(get_most_likely_walk(G, 'dog', 10))\n",
    "\n",
    "def get_least_likely_walk(G, start, walk_length):\n",
    "    \"\"\"\n",
    "    G: networkx.DiGraph -- semantic network of SWOW data\n",
    "    start: str -- name of node to start with\n",
    "    walk_length: the length of the walk to return.\n",
    "    \n",
    "    Return a list of length walk_length representing a walk. Do not include start in your\n",
    "    result. Each node in your walk should be the least likely node that the previous node has an\n",
    "    outgoing edge to. (Note that there will be nodes that have a zero probability given\n",
    "    the previous node, and are not connected to the previous node at all. These should\n",
    "    not be included.)\n",
    "    \n",
    "    Do not allow repeats in your walk. For example, say 'fox' is your start node and\n",
    "    'rock' is the least likely node to follow 'fox'. Even if 'fox' is also the least\n",
    "    likely node to follow 'rock', it should not be revisited after we've seen it. In\n",
    "    this case, you should select the second lowest weighted edge.\n",
    "    \"\"\"\n",
    "    walk = []\n",
    "    point = G[start]\n",
    "    prob = 1\n",
    "    for steps in point:\n",
    "        if point[steps]['weight'] < prob:\n",
    "            prob = point[steps]['weight']\n",
    "            step = steps\n",
    "    walk.append(step)\n",
    "    for i in range(walk_length-1):\n",
    "        after_step = G[step]\n",
    "        prob = 1\n",
    "        for steps in after_step:\n",
    "            if after_step[steps]['weight'] < prob and steps not in walk and steps != start:\n",
    "                mw = after_step[steps]['weight']\n",
    "                step = steps\n",
    "        walk.append(step)\n",
    "    \n",
    "    return walk \n",
    "print (\"Starting at dog, the least likely walk is:\")\n",
    "print(get_least_likely_walk(G, 'dog', 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d)\n",
    "\n",
    "Write a function `weighted_random_walk` to generate a random walk of length `walk_length` starting at node `start`. The probability of choosing the next node at each step in the walk should be based on your edge weights. You can implement this using `np.random.choice` (take a look at the documentation for the parameter `p`, which allows you to pass a list of weighted probabilities for the items to select from). These random walks (unlike in part c above) should allow revisiting nodes that have been visited before (since this is allowed in the Abbott et al. work).\n",
    "\n",
    "Your function should return a list of strings representing nodes visited. Implement your function according to the docstring below.\n",
    "\n",
    "Print the list of strings for a sample walk using the graph from part a with `start = 'animal'` and `walk_length = 50`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_random_walk(G, start, walk_length):\n",
    "    \"\"\"\n",
    "    G: networkx.DiGraph -- semantic network of SWOW data\n",
    "    start: str -- name of node to start with\n",
    "    walk_length: the length of the walk to return.\n",
    "    \n",
    "    Return a list of length walk_length representing a walk. Do not include start in your\n",
    "    result. Each node in your walk should be randomly selected based on the weights of the\n",
    "    outgoing edges of the previous node. A node can be visited more than once.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e)\n",
    "\n",
    "Write a function `get_animals_and_IRT` according to the docstring below. Your function should return a tuple of (description, animal_list), where:\n",
    " * description is a string description. Each line should include a valid `item`, as well as the `steps` between the item and the previous item (ie, the nodes on the path between each pair of responses). A response is a valid item if its label is in `ANIMAL_TO_CATEGORIES` (defined in `data/animals.py`) and it has not been seen previously in the walk.\n",
    " * animal_list is a list of tuples of `(item, IRT)`, where item is a valid item, and the IRT is the interitem response time, as defined in Abbott et al.\n",
    " \n",
    "For example, the walk `[animal, dog, pet, cat, dog, bone, dinosaur, lizard]` \n",
    "\n",
    "The description would be:\n",
    "\n",
    "`item: dog       steps:\n",
    " item: cat       steps: pet\n",
    " item: lizard    steps: dog, bone, dinosaur`\n",
    "\n",
    "And the animal_list would be:\n",
    "`[('dog', 1), ('cat', 2), ('lizard', 4)]`\n",
    "\n",
    "Note that `dog` occurs twice in the random walk, but is only listed as an `item` one time.  Also, we know `dinosaur` is an animal, but it's not listed in `ANIMAL_TO_CATEGORIES`.\n",
    "\n",
    "Run your function `weighted_random_walk` from part d (with `start = 'animal'` and `walk_length = 50`) until you find a walk with at least 6 valid `items`. Print the random walk, as well as the description and the animal_list returned by `get_animal_and_IRT` called on this walk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.animals import ANIMAL_TO_CATEGORIES\n",
    "\n",
    "\n",
    "def get_animal_and_IRT(node_list):\n",
    "    \"\"\"\n",
    "    node_list: list of string\n",
    "    \n",
    "    Return a tuple (description, animal_list). Where:\n",
    "      - description is a string in the format shown in the question description above\n",
    "      - animal_list is a list of tuples of (item, IRT), where item is a unique item, and count\n",
    "          is the interitem response time, as defined in Abott et al.\n",
    "    Ignore the nodes visited after the last unique item is found.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f)\n",
    "\n",
    "Here, you'll do an analysis of the IRT pattern in the random walks you generate, somewhat simplified from the Abbott et al. reading.  \n",
    "\n",
    "First, you'll need to recognize \"patch switches\": Check for each valid animal item whether it shares a category with the previous valid animal item in the walk.\n",
    "\n",
    "Second, you'll calculate the mean IRT across the entire walk (mIRT), as well as the mean difference from mIRT at each of three points: At valid animals that constitute a patch switch (position 1), as well as at valid animals one before a patch switch (position -1), and valid animals one after a patch switch (position 2).\n",
    "\n",
    "Finally, you'll average these values across a set of random walks.\n",
    "\n",
    "Implement this in the `graph_patch_switches` function below, according to the docstring.  (Note that the walks you pass into the function will be in the format of a list of (item, IRT) tuples returned by the function `get_animal_and_IRT` in part e).\n",
    "\n",
    "Call `graph_patch_switches` on the two input lists provide in the file `sample_rw_lists.py` and show the graph for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from data.animals import ANIMAL_TO_CATEGORIES\n",
    "from sample_rw_lists import sample1, sample2\n",
    "\n",
    "\n",
    "def generate_plot(triple_averages):\n",
    "    \"\"\"\n",
    "    triple_averages: list of length three representing the difference in mean IRTs at \"patch switch\"\n",
    "        positions compared to the overall mean IRT.\n",
    "        The order should be (position -1, position 1, position 2).\n",
    "        \n",
    "    Generate a bar graph of triple_averages.\n",
    "    \"\"\"\n",
    "    y_positions = np.arange(len(triple_averages))\n",
    "    plt.bar(y_positions, triple_averages, align='center', alpha=0.5)\n",
    "    plt.xticks(y_positions, ['position -1', 'position 1', 'position 2'])\n",
    "    plt.ylabel('difference from mean IRT')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def graph_patch_switches(walks):\n",
    "    \"\"\"\n",
    "    walks: list of list of tuple. Each inner list represents a walk. Each tuple in a walk\n",
    "        should be of the format (item, IRT), where item is a string representing a valid animal\n",
    "        in a walk and IRT is an integer indicating the time between this item and the previous one.\n",
    "    \n",
    "    Generate a graph of the average difference between overall mean IRT of a walk, and the mean IRT\n",
    "    at each of three patch switch positions:\n",
    "        position -1 corresponds to the items just before the first item in a patch switch, \n",
    "        position 1 corresponds to the first items in a patch switch, \n",
    "        position 2 corresponds to the items in the next position following those in position 1,\n",
    "            when those next items are in the same patch as the item in position 1.\n",
    "    Compute the mean IRT for each of the three positions, and the difference between those means\n",
    "        and the overall mean IRT of each walk.\n",
    "    Calculate the mean of these differences across all the random walks and plot those using the\n",
    "        generate_plot function defined above.\n",
    "    \n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (g)\n",
    "\n",
    "Now call `graph_patch_switches` on a list of N walks generated using the graph from part a with `start = 'animal'` and `walk_length = 50`. Only include walks containing 6 or more valid animal items in your analysis. (More specifically, you should generate walks until you have N walks that contain at least 6 valid animal items.)\n",
    "\n",
    "(i) Run your function with N=20 and show the graph.  Explain whether this matches the patch switch pattern seen in the human data and replicated by Abbott et al.\n",
    "\n",
    "(ii) Now run your function 10 more times with N=20.  Discuss whether the graphs across these different runs show the same pattern consistently.  Please do not include these graphs in what you turn in.\n",
    "\n",
    "(iii) Run your function two times with N=1000 random walks (this can take about 2 minutes each), and print the graphs for each of these two runs.  Explain whether the graphs match the patch switch pattern seen in the human data and replicated by Abbott et al.  Are the results consistent across the two runs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h)\n",
    "\n",
    "Write a script to call `get_animals_and_IRT` from part e on 20 random walks of length 50 starting at 'animal'. Write your script so that each random walk contains at least 6 valid animal items. Make sure to clearly number walks 1 - 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (i)\n",
    "\n",
    "(i) Name three different aspects of the paths you see in part h which contribute to the length of a path and which are not simple, direct associations with animal words.  For example, paths such as cat=>pet=>goldfish or tiger=>stripes=>zebra seem to match our intuition about what might trigger chains of responses in human semantic fluency. But you almost certainly found some paths in which chains of associations are longer due to some interesting factors.  Please identify three of these and show an example of each from your paths.\n",
    "\n",
    "(ii) Also, find a path that you think is particularly funny, and say why.\n",
    "\n",
    "(iii) How does your inspection of the 20 paths you generated influence your assessment of the findings in Abbott et al.? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
